import os
import uuid
from typing import Any, List, Iterable
from dotenv import load_dotenv

# Required:
# pip install -U langchain-azure-ai mem0 langchain-openai azure-cosmos azure-identity

from langchain_azure_ai.vectorstores import AzureCosmosDBNoSqlVectorSearch
from mem0 import Memory
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from azure.cosmos import CosmosClient
from azure.identity import DefaultAzureCredential
from langchain_core.documents import Document

# --- Load environment ---
load_dotenv()

# --- Config variables ---
azure_openai_api_key = os.getenv("AZURE_OPENAI_API_KEY")
azure_openai_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
azure_openai_api_version = os.getenv("AZURE_OPENAI_API_VERSION")
azure_openai_deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
azure_openai_embedding_deployment_name = os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME")
cosmosdb_endpoint = os.getenv("AZURE_COSMOSDB_ENDPOINT")
cosmosdb_database_name = os.getenv("AZURE_COSMOSDB_DATABASE_NAME")
cosmosdb_container_name = "mem0"
EMBEDDING_DIMENSIONS = 1536

# --- Wrapper Class ---
class CosmosDBMem0Wrapper(AzureCosmosDBNoSqlVectorSearch):
    """
    A wrapper to add detailed debugging and ensure compatibility with mem0
    by managing the 'data' field required by mem0 in the metadata.
    """
    def add_texts(
        self,
        texts: Iterable[str],
        metadatas: List[dict] | None = None,
        **kwargs: Any,
    ) -> List[str]:
        """
        Overrides add_texts to ensure the 'data' field required by mem0
        is present in the metadata before being stored.
        """
        print("\n[Wrapper.add_texts] Intercepted call to add texts...")
        if not metadatas:
            metadatas = [{} for _ in texts]
        
        # FIX: Ensure each metadata blob contains the 'data' field that mem0 will need on retrieval.
        # This metadata will be stored by the parent class.
        for metadata, text in zip(metadatas, texts):
            metadata['data'] = text 

        print(f"[Wrapper.add_texts] Handing off {len(list(texts))} documents to parent method.")
        return super().add_texts(texts=texts, metadatas=metadatas, **kwargs)

    def similarity_search_by_vector(
        self, embedding: List[float], k: int = 10, **kwargs: Any
    ) -> List[Document]:
        """
        Overrides similarity_search to ensure the returned documents
        are compatible with mem0's expectations.
        """
        print(f"\n[Wrapper.similarity_search] Intercepted vector search with k={k}...")
        
        # Get the standard documents from the parent search method
        results = super().similarity_search_by_vector(embedding=embedding, k=k, **kwargs)
        print(f"[Wrapper.similarity_search] Parent method returned {len(results)} results.")

        # FIX: Re-process the documents to ensure they have the 'data' field in metadata for mem0.
        # The parent class correctly populates doc.page_content. We ensure doc.metadata['data'] also has this content.
        for doc in results:
            if 'data' not in doc.metadata:
                doc.metadata['data'] = doc.page_content
            print(f"  - Match: {doc.page_content[:80]}...")
            
        return results

# --- Initialize services ---
print("Initializing clients...")

embedder = AzureOpenAIEmbeddings(
    azure_deployment=azure_openai_embedding_deployment_name,
    openai_api_version=azure_openai_api_version,
    azure_endpoint=azure_openai_endpoint,
    api_key=azure_openai_api_key
)

llm = AzureChatOpenAI(
    azure_deployment=azure_openai_deployment_name,
    api_version=azure_openai_api_version,
    azure_endpoint=azure_openai_endpoint,
    api_key=azure_openai_api_key,
)

credential = DefaultAzureCredential()
cosmos_client = CosmosClient(url=cosmosdb_endpoint, credential=credential)

vector_embedding_policy = {
    "vectorEmbeddings": [
        {"path": "/vectorContent", "dataType": "float32", "dimensions": EMBEDDING_DIMENSIONS, "distanceFunction": "cosine"},
    ]
}

indexing_policy = {
    "includedPaths": [{"path": "/*"}],
    "excludedPaths": [{"path": '/"_etag"/?'}],
    "vectorIndexes": [{"path": "/vectorContent", "type": "quantizedFlat"}],
}

# --- Vector store ---
print("Initializing Azure Cosmos DB for NoSQL Vector Store...")

# FIX: The constructor does NOT take text_key, embedding_key, etc.
# These arguments have been removed to fix the TypeError.
vector_store = CosmosDBMem0Wrapper(
    cosmos_client=cosmos_client,
    database_name=cosmosdb_database_name,
    container_name=cosmosdb_container_name,
    embedding=embedder,
    vector_embedding_policy=vector_embedding_policy,
    indexing_policy=indexing_policy,
)

print("Vector store initialized successfully.")

# --- Mem0 Config ---
config = {
    "vector_store": {
        "provider": "langchain",
        "config": {"client": vector_store},
    },
    "llm": {
        "provider": "langchain",
        "config": {"model": llm},
    },
    "embedder": {
        "provider": "langchain",
        "config": {"model": embedder},
    },
}

# --- Mem0 Setup ---
print("\nInitializing Mem0 from config...")
m = Memory.from_config(config)
print("Mem0 initialized.")

# --- Input Messages ---
messages = [
    {"role": "user", "content": "My favorite movies are The Matrix and Inception"},
    {"role": "assistant", "content": "Great choices!"},
    {"role": "user", "content": "I also love Blade Runner 2049"},
    {"role": "assistant", "content": "A modern classic!"}
]

# --- Add Memories ---
print("\n--- ADDING MEMORIES ---")
result = m.add(messages, user_id="alice", metadata={"category": "movies"})
print("\n[Result] Added memories:", result)

# --- Mem0 Search ---
print("\n--- SEARCHING MEMORIES ---")
search_results = m.search("What movies does the user like?", user_id="alice")
print("\n[Result] Search results:", search_results)

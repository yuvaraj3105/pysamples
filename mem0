import os
import uuid
from typing import Any, List, Iterable
from dotenv import load_dotenv

# Required:
# pip install -U langchain-azure-ai mem0 langchain-openai azure-cosmos azure-identity

from langchain_azure_ai.vectorstores import AzureCosmosDBNoSqlVectorSearch
from mem0 import Memory
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from azure.cosmos import CosmosClient
from azure.identity import DefaultAzureCredential
from langchain_core.documents import Document

# --- Load environment ---
load_dotenv()

# --- Config variables ---
azure_openai_api_key = os.getenv("AZURE_OPENAI_API_KEY")
azure_openai_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
azure_openai_api_version = os.getenv("AZURE_OPENAI_API_VERSION")
azure_openai_deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
azure_openai_embedding_deployment_name = os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME")
cosmosdb_endpoint = os.getenv("AZURE_COSMOSDB_ENDPOINT")
cosmosdb_database_name = os.getenv("AZURE_COSMOSDB_DATABASE_NAME")
cosmosdb_container_name = "mem0"

# --- Wrapper Class ---
class CosmosDBMem0Wrapper(AzureCosmosDBNoSqlVectorSearch):
    def add_texts(
        self,
        texts: Iterable[str],
        metadatas: List[dict] | None = None,
        **kwargs: Any,
    ) -> List[str]:
        print("\n[Debug] Adding texts...")
        if not metadatas:
            metadatas = [{} for _ in texts]

        formatted_metadatas = []
        doc_ids = []
        
        for idx, (text, metadata) in enumerate(zip(texts, metadatas)):
            # Create a new metadata dict with required fields
            formatted = metadata.copy()
            doc_id = formatted.get('id') or str(uuid.uuid4())
            formatted.update({
                'id': doc_id,
                'text': text,  # Store as 'text' for vector store
                'data': text,  # Store as 'data' for Mem0
                '_id': doc_id  # Backup ID field
            })
            
            formatted_metadatas.append(formatted)
            doc_ids.append(doc_id)
            print(f"[Debug] Preparing document {idx + 1}: ID={doc_id}, Content={text[:50]}...")

        # Call parent's add_texts with our formatted metadata
        try:
            result = super().add_texts(texts, formatted_metadatas, **kwargs)
            print(f"[Debug] Successfully added {len(doc_ids)} documents")
            return doc_ids
        except Exception as e:
            print(f"[Debug] Error in add_texts: {str(e)}")
            return []

    def similarity_search_by_vector(
        self, embedding: List[float], k: int = 10, **kwargs: Any
    ) -> List[Document]:
        try:
            print("\n[Debug] Starting vector search...")
            
            # Try direct vector search first
            results = self._collection.query_items(
                query="SELECT * FROM c",
                enable_scan_in_query=True,
                vector=embedding,
                top_k=k,
                vector_fields=[{
                    "path": "/vectorContent",
                    "distance_type": "CosineDistance"
                }],
                parameters=[],
            )
            
            # Convert results to list and print debug info
            docs_list = list(results)
            print(f"[Debug] Found {len(docs_list)} results")
            
            formatted_docs = []
            for item in docs_list:
                try:
                    # Extract or create metadata
                    metadata = {
                        "id": item.get("id") or str(uuid.uuid4()),
                        "data": item.get("text", ""),  # Use 'text' field as content
                        "score": item.get("_vector_score", 0)
                    }
                    
                    # Add any additional metadata
                    if "metadata" in item:
                        metadata.update(item["metadata"])
                    
                    # Create document
                    doc = Document(
                        page_content=item.get("text", ""),
                        metadata=metadata
                    )
                    formatted_docs.append(doc)
                    print(f"[Debug] Processed document: ID={metadata['id']}, Content={doc.page_content[:50]}...")
                except Exception as doc_error:
                    print(f"[Debug] Error processing document: {doc_error}")
                    continue
            
            return formatted_docs
        except Exception as e:
            print(f"[Debug] Error in similarity_search_by_vector: {str(e)}")
            return []

# --- Initialize services ---
print("Initializing clients...")

embedder = AzureOpenAIEmbeddings(
    azure_deployment=azure_openai_embedding_deployment_name,
    openai_api_version=azure_openai_api_version,
    azure_endpoint=azure_openai_endpoint,
    api_key=azure_openai_api_key
)

llm = AzureChatOpenAI(
    azure_deployment=azure_openai_deployment_name,
    api_version=azure_openai_api_version,
    azure_endpoint=azure_openai_endpoint,
    api_key=azure_openai_api_key,
)

credential = DefaultAzureCredential()
cosmos_client = CosmosClient(url=cosmosdb_endpoint, credential=credential)

EMBEDDING_DIMENSIONS = 1536

vector_embedding_policy = {
    "vectorEmbeddings": [
        {
            "path": "/vectorContent",
            "dataType": "float32",
            "dimensions": EMBEDDING_DIMENSIONS,
            "distanceFunction": "cosine",
        },
    ]
}

indexing_policy = {
    "includedPaths": [
        {"path": "/*"},
        {"path": "/metadata/*"},
        {"path": "/id/?"},
        {"path": "/data/?"}
    ],
    "excludedPaths": [{"path": '/"_etag"/?'}],
    "vectorIndexes": [
        {"path": "/vectorContent", "type": "quantizedFlat"},
    ],
}

# --- Vector store ---
print("Initializing Azure Cosmos DB for NoSQL Vector Store...")

vector_store = CosmosDBMem0Wrapper(
    cosmos_client=cosmos_client,
    database_name=cosmosdb_database_name,
    container_name=cosmosdb_container_name,
    embedding=embedder,
    vector_embedding_policy=vector_embedding_policy,
    indexing_policy=indexing_policy,
    cosmos_container_properties={"partition_key": {"paths": ["/id"], "kind": "Hash"}},
    cosmos_database_properties={},
    vector_search_fields={
        "text_field": "text",
        "embedding_field": "vectorContent",
        "metadata_field": "metadata",
    }
)

print("Vector store initialized successfully.")

# --- Mem0 Config ---
config = {
    "vector_store": {
        "provider": "langchain",
        "config": {"client": vector_store},
    },
    "llm": {
        "provider": "langchain",
        "config": {"model": llm},
    },
    "embedder": {
        "provider": "langchain",
        "config": {"model": embedder},
    },
}

# --- Mem0 Setup ---
print("\nInitializing Mem0 from config...")
m = Memory.from_config(config)
print("Mem0 initialized.")

# --- Input Messages ---
messages = [
    {"role": "user", "content": "My favorite movies are The Matrix and Inception"},
    {"role": "assistant", "content": "Great choices!"},
    {"role": "user", "content": "I also love Blade Runner 2049"},
    {"role": "assistant", "content": "A modern classic!"}
]

# --- Add Memories ---
print("\nAdding memories...")
result = m.add(messages, user_id="alice", metadata={"category": "movies"})
print("Added memories:", result)

# --- Mem0 Search ---
print("\nSearching for memories...")
search_results = m.search("What movies does the user like?", user_id="alice")
print("Search results:", search_results)

# --- Direct Vector Search Debug ---
print("\n[Debug] Running comprehensive vector search test:")

# Test direct document retrieval
print("\n1. Testing direct document retrieval:")
try:
    results = vector_store._collection.query_items(
        query="SELECT * FROM c",
        enable_scan_in_query=True,
        parameters=[],
    )
    docs = list(results)
    print(f"Found {len(docs)} total documents in collection")
    for doc in docs:
        print(f"Document: ID={doc.get('id')}, Text={doc.get('text', '')[:50]}...")
except Exception as e:
    print(f"Error in direct retrieval: {str(e)}")

# Test vector search
print("\n2. Testing vector search:")
query = "What movies does the user like?"
try:
    query_embedding = embedder.embed_query(query)
    print("Generated query embedding successfully")
    
    results = vector_store.similarity_search_by_vector(query_embedding, k=10)
    print(f"\nFound {len(results)} results via vector search")
    for doc in results:
        print(f"Match (score={doc.metadata.get('score', 'N/A')}):")
        print(f"  ID: {doc.metadata.get('id', 'N/A')}")
        print(f"  Content: {doc.page_content[:100]}...")
except Exception as e:
    print(f"Error in vector search test: {str(e)}")

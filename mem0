import os
import uuid
from typing import Any, List, Iterable
from dotenv import load_dotenv

# Required:
# pip install -U langchain-azure-ai mem0 langchain-openai azure-cosmos azure-identity

from langchain_azure_ai.vectorstores import AzureCosmosDBNoSqlVectorSearch
from mem0 import Memory
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from azure.cosmos import CosmosClient
from azure.identity import DefaultAzureCredential
from langchain_core.documents import Document

# --- Load environment ---
load_dotenv()

# --- Config variables ---
azure_openai_api_key = os.getenv("AZURE_OPENAI_API_KEY")
azure_openai_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
azure_openai_api_version = os.getenv("AZURE_OPENAI_API_VERSION")
azure_openai_deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
azure_openai_embedding_deployment_name = os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME")
cosmosdb_endpoint = os.getenv("AZURE_COSMOSDB_ENDPOINT")
cosmosdb_database_name = os.getenv("AZURE_COSMOSDB_DATABASE_NAME")
cosmosdb_container_name = "mem0"
EMBEDDING_DIMENSIONS = 1536

# --- Wrapper Class ---
class CosmosDBMem0Wrapper(AzureCosmosDBNoSqlVectorSearch):
    """
    A wrapper to add detailed debugging and ensure compatibility with mem0.
    """
    def add_texts(
        self,
        texts: Iterable[str],
        metadatas: List[dict] | None = None,
        **kwargs: Any,
    ) -> List[str]:
        """
        Overrides add_texts to inject required metadata fields for mem0 and add debug prints.
        """
        print("\n[Wrapper.add_texts] Intercepted call to add texts...")
        if not metadatas:
            metadatas = [{} for _ in texts]

        # FIX: The parent's add_texts will use the `text_key` we provide at initialization
        # to handle the text. We just need to ensure the metadata has the ID.
        # mem0 relies on getting the original text back, which we store in the 'data' field.
        for metadata, text in zip(metadatas, texts):
            if "id" not in metadata:
                metadata["id"] = str(uuid.uuid4())
            metadata["data"] = text # mem0 needs this field to reconstruct the memory

        print(f"[Wrapper.add_texts] Handing off {len(list(texts))} documents to parent method.")
        try:
            # Call the original, working add_texts method from the parent class
            added_ids = super().add_texts(texts=texts, metadatas=metadatas, **kwargs)
            print(f"[Wrapper.add_texts] Successfully added documents. IDs: {added_ids}")
            return added_ids
        except Exception as e:
            print(f"[Wrapper.add_texts] ERROR in parent add_texts: {e}")
            import traceback
            print(traceback.format_exc())
            return []

    def similarity_search_by_vector(
        self, embedding: List[float], k: int = 10, **kwargs: Any
    ) -> List[Document]:
        """
        Try super().similarity_search; if not implemented, fallback to Cosmos DB SDK vector search.
        """
        print(f"\n[Wrapper.similarity_search] Intercepted vector search with k={k}...")
        try:
            # Try the parent's similarity_search method
            try:
                print("[Wrapper.similarity_search] Trying super().similarity_search...")
                results = super().similarity_search(
                    "",  # query string (not used if embedding is provided)
                    k=k,
                    embedding=embedding,
                    **kwargs
                )
                # Ensure every Document has a valid string id
                for doc in results:
                    doc.metadata["id"] = str(doc.metadata.get("id") or uuid.uuid4())
                print(f"[Wrapper.similarity_search] Parent method returned {len(results)} results.")
                for doc in results:
                    print(f"  - Match: {doc.page_content}")
                return results
            except NotImplementedError:
                print("[Wrapper.similarity_search] super().similarity_search not implemented. Falling back to Cosmos DB SDK.")
                # Fallback: Use Cosmos DB SDK for vector search
                container = self._container
                # Cosmos DB vector search syntax may vary; adjust as needed for your SDK version
                results = container.query_items(
                    query="SELECT * FROM c",
                    enable_cross_partition_query=True,
                    parameters=[],
                    vector=embedding,
                    top_k=k,
                    vector_fields=[{
                        "path": "/vectorContent",
                        "distance_type": "CosineDistance"
                    }]
                )
                docs_list = list(results)
                print(f"[Wrapper.similarity_search] Cosmos DB SDK returned {len(docs_list)} results.")
                formatted_docs = []
                for item in docs_list:
                    metadata = {
                        "id": item.get("id") or str(uuid.uuid4()),
                        "data": item.get("text", "") or item.get("page_content", ""),
                        "score": item.get("_vector_score", 0)
                    }
                    if "metadata" in item:
                        metadata.update(item["metadata"])
                    content = (
                        item.get("text", "") or 
                        item.get("page_content", "") or 
                        item.get("content", "") or 
                        metadata.get("data", "")
                    )
                    doc = Document(
                        page_content=content,
                        metadata=metadata
                    )
                    # Ensure every Document has a valid string id
                    doc.metadata["id"] = str(doc.metadata.get("id") or uuid.uuid4())
                    formatted_docs.append(doc)
                    print(f"  - Fallback Match (Score: {metadata['score']}): {content}")
                return formatted_docs
        except Exception as e:
            print(f"[Wrapper.similarity_search] ERROR in parent search: {str(e)}")
            import traceback
            print(traceback.format_exc())
            return []


# --- Initialize services ---
print("Initializing clients...")

embedder = AzureOpenAIEmbeddings(
    azure_deployment=azure_openai_embedding_deployment_name,
    openai_api_version=azure_openai_api_version,
    azure_endpoint=azure_openai_endpoint,
    api_key=azure_openai_api_key
)

llm = AzureChatOpenAI(
    azure_deployment=azure_openai_deployment_name,
    api_version=azure_openai_api_version,
    azure_endpoint=azure_openai_endpoint,
    api_key=azure_openai_api_key,
)

credential = DefaultAzureCredential()
cosmos_client = CosmosClient(url=cosmosdb_endpoint, credential=credential)

vector_embedding_policy = {
    "vectorEmbeddings": [
        {"path": "/vectorContent", "dataType": "float32", "dimensions": EMBEDDING_DIMENSIONS, "distanceFunction": "cosine"},
    ]
}

indexing_policy = {
    "includedPaths": [{"path": "/*"}],
    "excludedPaths": [{"path": '/"_etag"/?'}],
    "vectorIndexes": [{"path": "/vectorContent", "type": "quantizedFlat"}],
}

# --- Vector store ---
print("Initializing Azure Cosmos DB for NoSQL Vector Store...")

# FIX: Correctly initialize the vector store with direct keyword arguments.
# Do NOT use a `vector_search_fields` dictionary.
vector_store = CosmosDBMem0Wrapper(
    cosmos_client=cosmos_client,
    database_name=cosmosdb_database_name,
    container_name=cosmosdb_container_name,
    embedding=embedder,
    vector_embedding_policy=vector_embedding_policy,
    indexing_policy=indexing_policy,
    cosmos_container_properties={"partition_key": {"paths": ["/id"], "kind": "Hash"}},
    cosmos_database_properties={},
    vector_search_fields={
        "text_field": "text",
        "embedding_field": "vectorContent",
        "metadata_field": "metadata",
    }
)

print("Vector store initialized successfully.")

# --- Clean up all documents in the container before running ---
print("Cleaning up all documents in the container before running...")
container = vector_store._container
# Query all documents (cross-partition)
docs = list(container.query_items(
    query="SELECT * FROM c",
    enable_cross_partition_query=True
))
print(f"Found {len(docs)} documents in the container before cleanup.")
deleted_count = 0
for doc in docs:
    doc_id = doc.get('id')
    print(f"Found document with id: {doc_id}")
    if not doc_id:
        print(f"Skipping document with missing id: {doc}")
        continue
    try:
        container.delete_item(item=doc_id, partition_key=doc_id)
        deleted_count += 1
    except Exception as e:
        print(f"Failed to delete document {doc_id}: {e}")
print(f"Deleted {deleted_count} documents from the container.")

# --- Mem0 Config ---
config = {
    "vector_store": {
        "provider": "langchain",
        "config": {"client": vector_store},
    },
    "llm": {
        "provider": "langchain",
        "config": {"model": llm},
    },
    "embedder": {
        "provider": "langchain",
        "config": {"model": embedder},
    },
}

# --- Mem0 Setup ---
print("\nInitializing Mem0 from config...")
m = Memory.from_config(config)
print("Mem0 initialized.")

# --- Input Messages ---
messages = [
    {"role": "user", "content": "My favorite movies are The Matrix and Inception"},
    {"role": "assistant", "content": "Great choices!"},
    {"role": "user", "content": "I also love Blade Runner 2049"},
    {"role": "assistant", "content": "A modern classic!"}
]

# --- Add Memories ---
print("\n--- ADDING MEMORIES ---")
result = m.add(messages, user_id="alice", metadata={"category": "movies"})
print("\n[Result] Added memories:", result)

# --- Mem0 Search ---
print("\n--- SEARCHING MEMORIES ---")
search_results = m.search("What movies does the user like?", user_id="alice")
print("\n[Result] Search results:", search_results)

# --- Direct Vector Search Debug ---
print("\n[Debug] Running comprehensive vector search test:")

# Test direct document retrieval
print("\n1. Testing direct document retrieval:")
try:
    container = vector_store._container
    print(f"[Debug] Using container: {container.id}")
    results = container.query_items(
        query="SELECT * FROM c",
        enable_cross_partition_query=True,
        parameters=[],
    )
    docs = list(results)
    print(f"Found {len(docs)} total documents in collection")
    for doc in docs:
        print(f"Document: ID={doc.get('id')}, Text={doc.get('text', '')}")
        content = (
            doc.get("text", "") or 
            doc.get("page_content", "") or 
            doc.get("content", "") or 
            doc.get("data", "")
        )
        print(f"Document: ID={doc.get('id')}, Text={content}")
except Exception as e:
    print(f"Error in direct retrieval: {str(e)}")
    import traceback
    print(f"Full error: {traceback.format_exc()}")

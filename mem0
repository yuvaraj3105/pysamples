import os
import uuid
from typing import Any, List, Iterable
from dotenv import load_dotenv

# Required:
# pip install -U langchain-azure-ai mem0 langchain-openai azure-cosmos azure-identity

from langchain_azure_ai.vectorstores import AzureCosmosDBNoSqlVectorSearch
from mem0 import Memory
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from azure.cosmos import CosmosClient
from azure.identity import DefaultAzureCredential
from langchain_core.documents import Document

# --- Load environment ---
load_dotenv()

# --- Config variables ---
azure_openai_api_key = os.getenv("AZURE_OPENAI_API_KEY")
azure_openai_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
azure_openai_api_version = os.getenv("AZURE_OPENAI_API_VERSION")
azure_openai_deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
azure_openai_embedding_deployment_name = os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME")
cosmosdb_endpoint = os.getenv("AZURE_COSMOSDB_ENDPOINT")
cosmosdb_database_name = os.getenv("AZURE_COSMOSDB_DATABASE_NAME")
cosmosdb_container_name = "mem0"

# --- Wrapper Class ---
class CosmosDBMem0Wrapper(AzureCosmosDBNoSqlVectorSearch):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # Initialize container reference
        self._mem0_container = None

    @property
    def container(self):
        """Get the container reference, initializing if needed."""
        if self._mem0_container is None:
            try:
                # Access the protected attributes from parent class
                database = self._cosmos_client.get_database_client(self._database_name)
                self._mem0_container = database.get_container_client(self._container_name)
                print(f"[Debug] Successfully initialized container: {self._container_name}")
            except Exception as e:
                print(f"[Debug] Error initializing container: {str(e)}")
                import traceback
                print(f"[Debug] Full error: {traceback.format_exc()}")
                raise
        return self._mem0_container

    def add_texts(
        self,
        texts: Iterable[str],
        metadatas: List[dict] | None = None,
        **kwargs: Any,
    ) -> List[str]:
        print("\n[Debug] Adding texts...")
        if not metadatas:
            metadatas = [{} for _ in texts]

        formatted_metadatas = []
        doc_ids = []
        
        # Convert texts to list if it's not already
        texts_list = list(texts)
        
        # Get embeddings for all texts at once
        try:
            embeddings = self._embedding.embed_documents(texts_list)
            print(f"[Debug] Generated embeddings for {len(texts_list)} documents")
        except Exception as e:
            print(f"[Debug] Error generating embeddings: {str(e)}")
            return []

        for idx, (text, metadata, embedding) in enumerate(zip(texts_list, metadatas, embeddings)):
            try:
                # Create a new metadata dict with required fields
                formatted = metadata.copy()
                doc_id = formatted.get('id') or str(uuid.uuid4())
                
                # Create the document with all required fields
                document = {
                    'id': doc_id,
                    'text': text,
                    'data': text,
                    'metadata': formatted,
                    'vectorContent': list(map(float, embedding)),  # Ensure vector is float list
                    'page_content': text,
                    'embedding_dimensions': len(embedding)
                }
                print(f"[Debug] Document structure: {document.keys()}")
                
                # Store document directly
                try:
                    self.container.create_item(body=document)
                    doc_ids.append(doc_id)
                    print(f"[Debug] Successfully stored document {idx + 1}: ID={doc_id}")
                except Exception as store_error:
                    print(f"[Debug] Error storing document: {store_error}")
                    continue
                
            except Exception as doc_error:
                print(f"[Debug] Error processing document {idx + 1}: {doc_error}")
                continue

        print(f"[Debug] Successfully added {len(doc_ids)} documents")
        return doc_ids

    def similarity_search_by_vector(
        self, embedding: List[float], k: int = 10, **kwargs: Any
    ) -> List[Document]:
        try:
            print("\n[Debug] Starting vector search...")
            
            # Perform vector search directly using Cosmos DB
            query = """
                SELECT TOP @k *
                FROM c
                WHERE IS_DEFINED(c.vectorContent)
            """
            
            parameters = [
                {"name": "@k", "value": k}
            ]
            
            # Add vector search options
            options = {
                'enableCrossPartitionQuery': True,
                'consistencyLevel': 'Session',
                'vectorSearchOptions': {
                    'vector': embedding,
                    'fields': [{
                        'path': '/vectorContent',
                        'similarity': 'cosine'
                    }]
                }
            }
            
            print("[Debug] Vector search options:", options)
            
            results = list(self.container.query_items(
                query=query,
                parameters=parameters,
                **options
            ))
            
            print(f"[Debug] Found {len(results)} results")
            
            # Format documents for Mem0
            formatted_docs = []
            for item in results:
                try:
                    # Extract metadata and ensure required fields
                    metadata = item.get('metadata', {}).copy()
                    metadata.update({
                        'id': item.get('id', str(uuid.uuid4())),
                        'data': item.get('text', ''),
                        'score': item.get('_vector_score', 0)
                    })
                    
                    # Get content from available fields
                    content = (
                        item.get('text', '') or 
                        item.get('page_content', '') or 
                        item.get('data', '')
                    )
                    
                    # Create formatted document
                    doc = Document(
                        page_content=content,
                        metadata=metadata
                    )
                    formatted_docs.append(doc)
                    print(f"[Debug] Processed result: ID={metadata['id']}, Score={metadata['score']}")
                except Exception as doc_error:
                    print(f"[Debug] Error processing result: {doc_error}")
                    continue
            
            return formatted_docs
        except Exception as e:
            print(f"[Debug] Error in similarity_search_by_vector: {str(e)}")
            import traceback
            print(f"[Debug] Full error: {traceback.format_exc()}")
            return []

# --- Initialize services ---
print("Initializing clients...")

embedder = AzureOpenAIEmbeddings(
    azure_deployment=azure_openai_embedding_deployment_name,
    openai_api_version=azure_openai_api_version,
    azure_endpoint=azure_openai_endpoint,
    api_key=azure_openai_api_key
)

llm = AzureChatOpenAI(
    azure_deployment=azure_openai_deployment_name,
    api_version=azure_openai_api_version,
    azure_endpoint=azure_openai_endpoint,
    api_key=azure_openai_api_key,
)

credential = DefaultAzureCredential()
cosmos_client = CosmosClient(url=cosmosdb_endpoint, credential=credential)

EMBEDDING_DIMENSIONS = 1536

vector_embedding_policy = {
    "vectorEmbeddings": [
        {
            "path": "/vectorContent",
            "dataType": "float32",
            "dimensions": EMBEDDING_DIMENSIONS,
            "distanceFunction": "cosine",
            "kind": "COSINE"
        },
    ]
}

indexing_policy = {
    "indexingMode": "consistent",
    "automatic": True,
    "includedPaths": [
        {"path": "/*"},
        {"path": "/metadata/*"},
        {"path": "/id/?"},
        {"path": "/data/?"},
        {"path": "/vectorContent/?"}
    ],
    "excludedPaths": [
        {"path": '/"_etag"/?'}
    ],
    "vectorIndexConfigs": [
        {
            "path": "/vectorContent/*",
            "type": "HNSW",
            "config": {
                "dimensions": EMBEDDING_DIMENSIONS,
                "metric": "cosine"
            }
        }
    ]
}

# --- Vector store ---
print("Initializing Azure Cosmos DB for NoSQL Vector Store...")

vector_store = CosmosDBMem0Wrapper(
    cosmos_client=cosmos_client,
    database_name=cosmosdb_database_name,
    container_name=cosmosdb_container_name,
    embedding=embedder,
    vector_embedding_policy=vector_embedding_policy,
    indexing_policy=indexing_policy,
    cosmos_container_properties={"partition_key": {"paths": ["/id"], "kind": "Hash"}},
    cosmos_database_properties={},
    vector_search_fields={
        "text_field": "text",
        "embedding_field": "vectorContent",
        "metadata_field": "metadata",
    }
)

print("Vector store initialized successfully.")

# --- Mem0 Config ---
config = {
    "vector_store": {
        "provider": "langchain",
        "config": {"client": vector_store},
    },
    "llm": {
        "provider": "langchain",
        "config": {"model": llm},
    },
    "embedder": {
        "provider": "langchain",
        "config": {"model": embedder},
    },
}

# --- Mem0 Setup ---
print("\nInitializing Mem0 from config...")
m = Memory.from_config(config)
print("Mem0 initialized.")

# --- Input Messages ---
messages = [
    {"role": "user", "content": "My favorite movies are The Matrix and Inception"},
    {"role": "assistant", "content": "Great choices!"},
    {"role": "user", "content": "I also love Blade Runner 2049"},
    {"role": "assistant", "content": "A modern classic!"}
]

# --- Add Memories ---
print("\nAdding memories...")
result = m.add(messages, user_id="alice", metadata={"category": "movies"})
print("Added memories:", result)

# --- Mem0 Search ---
print("\nSearching for memories...")
search_results = m.search("What movies does the user like?", user_id="alice")
print("Search results:", search_results)

# --- Direct Vector Search Debug ---
print("\n[Debug] Running comprehensive vector search test:")

# Test direct document retrieval
print("\n1. Testing direct document retrieval:")
try:
    container = vector_store.container
    print(f"[Debug] Using container: {container.id}")
    
    # Query with cross-partition enabled
    results = list(container.query_items(
        query="SELECT * FROM c WHERE IS_DEFINED(c.vectorContent)",
        enable_cross_partition_query=True,
        parameters=[]
    ))
    
    print(f"Found {len(results)} total documents in collection")
    for doc in results:
        content = (
            doc.get("text", "") or 
            doc.get("page_content", "") or 
            doc.get("content", "") or 
            doc.get("data", "")
        )
        print(f"Document: ID={doc.get('id')}, Text={content[:50]}...")
        print(f"Vector dimensions: {len(doc.get('vectorContent', []))}")
except Exception as e:
    print(f"Error in direct retrieval: {str(e)}")
    import traceback
    print(f"Full error: {traceback.format_exc()}")

# Test vector search
print("\n2. Testing vector search:")
query = "What movies does the user like?"
try:
    query_embedding = embedder.embed_query(query)
    print("Generated query embedding successfully")
    
    results = vector_store.similarity_search_by_vector(query_embedding, k=10)
    print(f"\nFound {len(results)} results via vector search")
    for doc in results:
        print(f"Match (score={doc.metadata.get('score', 'N/A')}):")
        print(f"  ID: {doc.metadata.get('id', 'N/A')}")
        print(f"  Content: {doc.page_content[:100]}...")
except Exception as e:
    print(f"Error in vector search test: {str(e)}")
